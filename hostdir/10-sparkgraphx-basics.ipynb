{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8eaa1f8-d47a-4aa1-ba2f-6371f1e54c57",
   "metadata": {},
   "source": [
    "# EX10-GRAPH: Spark GraphX (Scala API)\n",
    "\n",
    "Your assignment: complete the `TODO`'s and include also the **output of each cell**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbf2fc-9768-4654-827a-be00c3064514",
   "metadata": {},
   "source": [
    "### Step 1: Almond configuration for Spark/Scala kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3c22a-1489-4c1f-95ca-f10ac1b983c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.5.0`\n",
    "import $ivy.`org.apache.spark::spark-graphx:3.5.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1228f2-5938-49fb-9b07-ad599cef9d15",
   "metadata": {},
   "source": [
    "### Step 2: Start Spark session (notice that this is specific for Almond Notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190a0b3-113a-4de4-bd56-7162f67c9f7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70998870-c7d4-4018-a93e-b54b62609e05",
   "metadata": {},
   "source": [
    "### Step 3: Spark Official Doc Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20cd63-afd0-4a0e-b475-1e28707fa73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.graphx._\n",
    "// To make some of the examples work we will also need RDD\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "class VertexProperty()\n",
    "case class UserProperty(val name: String) extends VertexProperty\n",
    "case class ProductProperty(val name: String, val price: Double) extends VertexProperty\n",
    "\n",
    "val sc = spark.sparkContext\n",
    "\n",
    "// Create an RDD for the vertices\n",
    "val users: RDD[(VertexId, (String, String))] =\n",
    "  sc.parallelize(Seq((3L, (\"rxin\", \"student\")), (7L, (\"jgonzal\", \"postdoc\")),\n",
    "                       (5L, (\"franklin\", \"prof\")), (2L, (\"istoica\", \"prof\"))))\n",
    "// Create an RDD for edges\n",
    "val relationships: RDD[Edge[String]] =\n",
    "  sc.parallelize(Seq(Edge(3L, 7L, \"collab\"),    Edge(5L, 3L, \"advisor\"),\n",
    "                       Edge(2L, 5L, \"colleague\"), Edge(5L, 7L, \"pi\")))\n",
    "// Define a default user in case there are relationship with missing user\n",
    "val defaultUser = (\"John Doe\", \"Missing\")\n",
    "// Build the initial Graph\n",
    "val graph = Graph(users, relationships, defaultUser)\n",
    "\n",
    "graph.vertices.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6595e36-4471-42a7-a8c0-06491f8341b3",
   "metadata": {},
   "source": [
    "### Step 4: Try out other constructs and capabilities of GraphX from the official doc (`TODO`)\n",
    "\n",
    "Include other commands, see what it does. Try out the Pregel API, etc.\n",
    "\n",
    "[GraphX Documentation](https://spark.apache.org/docs/latest/graphx-programming-guide.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba73905-25e1-45d6-b130-7fdbc8a0c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ... show your work (remember: this a Scala notebook, not Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65baf3e-60c2-499b-a847-ca538752c682",
   "metadata": {},
   "source": [
    "### Step 5: Modeling another graph\n",
    "\n",
    "Exercise 3 (data models) asked you to build a graph from nobel data. The challenge is to use everything you have learned so far (Spark core, SparkSQL) to read that data and build the same graph using Spark/GraphX data type. Things to remember: nobel data is available in JSON format, back then we used Python lib networkx to model that graph. Now you must do this in Spark, back to back.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f77579-d804-4628-a0e0-ca4d2a293528",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ... show your work (remember: this a Scala notebook, not Python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
